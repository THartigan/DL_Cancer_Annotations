2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_setup.py:_flush():67] Current SDK version is 0.19.7.dev1
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_setup.py:_flush():67] Configure stats pid to 158248
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_setup.py:_flush():67] Loading settings from /home/tjh200/.config/wandb/settings
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_setup.py:_flush():67] Loading settings from /local/scratch/code/TROPHY/colon_data_analysis/CRIME/Develop/wandb/settings
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_init.py:setup_run_log_directory():647] Logging user logs to /local/scratch/code/TROPHY/colon_data_analysis/CRIME/Develop/wandb/run-20250401_111221-lbdpdwuy/logs/debug.log
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to /local/scratch/code/TROPHY/colon_data_analysis/CRIME/Develop/wandb/run-20250401_111221-lbdpdwuy/logs/debug-internal.log
2025-04-01 11:12:21,336 INFO    MainThread:158248 [wandb_init.py:monkeypatch_ipython():599] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x734e9c49bcd0>
2025-04-01 11:12:21,337 INFO    MainThread:158248 [wandb_init.py:init():761] calling init triggers
2025-04-01 11:12:21,521 INFO    MainThread:158248 [wandb_init.py:init():766] wandb.init called with sweep_config: {}
config: {'prop_to_use': 0.05, 'learning_rate': 0.0005, 'weight_decay': 0.1, 'scheduler_step_size': 10, 'scheduler_gamma': 0.5, 'num_epochs': 10, 'entropy_weights': tensor([1.0000, 0.7137, 1.0000, 1.0000]), 'model_class': 'SCNN_TPL3', 'batch_size': 2048, 'early_stop': False, 'training_fold_number': -1, 'val_fold_number': 1, 'number_of_training_folds': 3, 'validation_test_folds': 2, 'dataset': 'data.npy', 'apriori_relevance': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'input_channels': 1, 'leak_rate': 0.1, 'dropout_rate': 0.7, '_wandb': {}}
2025-04-01 11:12:21,521 INFO    MainThread:158248 [wandb_init.py:init():784] starting backend
2025-04-01 11:12:21,521 INFO    MainThread:158248 [wandb_init.py:init():788] sending inform_init request
2025-04-01 11:12:21,523 INFO    MainThread:158248 [backend.py:_multiprocessing_setup():97] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-01 11:12:21,523 INFO    MainThread:158248 [wandb_init.py:init():803] backend started and connected
2025-04-01 11:12:21,526 INFO    MainThread:158248 [wandb_run.py:_label_probe_notebook():1204] probe notebook
2025-04-01 11:12:21,528 INFO    MainThread:158248 [wandb_init.py:init():896] updated telemetry
2025-04-01 11:12:21,534 INFO    MainThread:158248 [wandb_init.py:init():920] communicating run to backend with 90.0 second timeout
2025-04-01 11:12:21,880 INFO    MainThread:158248 [wandb_init.py:init():995] starting run threads in backend
2025-04-01 11:12:21,999 INFO    MainThread:158248 [wandb_run.py:_console_start():2377] atexit reg
2025-04-01 11:12:22,000 INFO    MainThread:158248 [wandb_run.py:_redirect():2227] redirect: wrap_raw
2025-04-01 11:12:22,001 INFO    MainThread:158248 [wandb_run.py:_redirect():2292] Wrapping output streams.
2025-04-01 11:12:22,001 INFO    MainThread:158248 [wandb_run.py:_redirect():2317] Redirects installed.
2025-04-01 11:12:22,002 INFO    MainThread:158248 [wandb_init.py:init():1037] run started, returning control to user process
2025-04-01 11:12:25,471 INFO    MainThread:158248 [jupyter.py:save_ipynb():386] not saving jupyter notebook
2025-04-01 11:12:25,471 INFO    MainThread:158248 [wandb_init.py:_pause_backend():564] pausing backend
